# Architectural Components of MCP MCP的架构组件
In the previous section, we discussed the key concepts and terminology of MCP. Now, let’s dive deeper into the architectural components that make up the MCP ecosystem.

在上一节中，我们讨论了MCP的关键概念和术语。现在，让我们更深入地了解构成MCP生态系统的架构组件。

# Host, Client, and Server 主机、客户端和服务器

The Model Context Protocol (MCP) is built on a client-server architecture that enables structured communication between AI models and external systems.

模型上下文协议（MCP）基于客户端-服务器架构构建，能够实现人工智能模型与外部系统之间的结构化通信。

<img width="865" height="300" alt="image" src="https://github.com/user-attachments/assets/79a81637-10c7-4152-a69d-57f366465668" />


The MCP architecture consists of three primary components, each with well-defined roles and responsibilities: Host, Client, and Server. We touched on these in the previous section, but let’s dive deeper into each component and their responsibilities.


# Host 主机
The Host is the user-facing AI application that end-users interact with directly.

宿主是面向用户的人工智能应用程序，最终用户可以直接与之交互。


Examples include: 示例包括：

- AI Chat apps like OpenAI ChatGPT or Anthropic’s Claude Desktop
- 像OpenAI ChatGPT或Anthropic的Claude Desktop这类人工智能聊天应用程序
- AI-enhanced IDEs like Cursor, or integrations to tools like Continue.dev
- 像Cursor这样的人工智能增强型集成开发环境，或者像Continue.dev这样的工具集成
- Custom AI agents and applications built in libraries like LangChain or smolagents
- 使用LangChain或smolagents等库构建的自定义人工智能智能体和应用程序

The Host’s responsibilities include:

主持人的职责包括：

- Managing user interactions and permissions
- 管理用户交互和权限
- Initiating connections to MCP Servers via MCP Clients
- 通过MCP客户端初始化与MCP服务器的连接
- Orchestrating the overall flow between user requests, LLM processing, and external tools
- 协调用户请求、大语言模型处理和外部工具之间的整体流程
- Rendering results back to users in a coherent format
- 以连贯的格式向用户返回渲染结果


In most cases, users will select their host application based on their needs and preferences. For example, a developer may choose Cursor for its powerful code editing capabilities, while domain experts may use custom applications built in smolagents.

在大多数情况下，用户会根据自己的需求和偏好选择宿主应用程序。例如，开发者可能会选择Cursor，因为它具有强大的代码编辑功能，而领域专家可能会使用基于smolagents构建的自定义应用程序。


# Client 客户端

The Client is a component within the Host application that manages communication with a specific MCP Server. Key characteristics include:

客户端是主机应用程序中管理与特定MCP服务器通信的组件。其主要特点包括：

- Each Client maintains a 1:1 connection with a single Server
- Handles the protocol-level details of MCP communication
- Acts as the intermediary between the Host’s logic and the external Server

# Server 服务器
The Server is an external program or service that exposes capabilities to AI models via the MCP protocol. Servers:

- Provide access to specific external tools, data sources, or services
- Act as lightweight wrappers around existing functionality
- Can run locally (on the same machine as the Host) or remotely (over a network)
- 可以在本地运行（与主机在同一台机器上）或远程运行（通过网络）
- Expose their capabilities in a standardized format that Clients can discover and use

# Communication Flow
Let’s examine how these components interact in a typical MCP workflow:

通信流程通信流程通信流程

让我们来看看这些组件在典型的MCP工作流中是如何交互的：

In the next section, we’ll dive deeper into the communication protocol that enables these components with practical examples.

- 1.User Interaction: The user interacts with the Host application, expressing an intent or query.

- 2.Host Processing: The Host processes the user’s input, potentially using an LLM to understand the request and determine which external capabilities might be needed

主机处理：主机处理用户的输入，可能会使用大语言模型来理解请求并确定可能需要哪些外部功能

Client Connection: The Host directs its Client component to connect to the appropriate Server(s).

客户端连接：主机指示其客户端组件连接到相应的服务器。

Capability Discovery: The Client queries the Server to discover what capabilities (Tools, Resources, Prompts) it offers.

能力发现：客户端向服务器查询，以发现其提供的能力（工具、资源、提示词）。

Capability Invocation: Based on the user’s needs or the LLM’s determination, the Host instructs the Client to invoke specific capabilities from the Server.

能力调用：根据用户的需求或大语言模型（LLM）的判断，主机指示客户端从服务器调用特定能力。

Server Execution: The Server executes the requested functionality and returns results to the Client.

服务器执行：服务器执行请求的功能，并将结果返回给客户端。


Result Integration: The Client relays these results back to the Host, which incorporates them into the context for the LLM or presents them directly to the user.

结果整合：客户端将这些结果转发回主机，主机将它们整合到LLM的上下文中，或直接呈现给用户。


A key advantage of this architecture is its modularity. A single Host can connect to multiple Servers simultaneously via different Clients. New Servers can be added to the ecosystem without requiring changes to existing Hosts. Capabilities can be easily composed across different Servers.


As we discussed in the previous section, this modularity transforms the traditional M×N integration problem (M AI applications connecting to N tools/services) into a more manageable M+N problem, where each Host and Server needs to implement the MCP standard only once.

正如我们在上一节中讨论的那样，这种模块化将传统的M×N集成问题（M个AI应用程序连接到N个工具/服务）转变为一个更易于管理的M+N问题，其中每个主机和服务器只需实现一次MCP标准。


The architecture might appear simple, but its power lies in the standardization of the communication protocol and the clear separation of responsibilities between components. This design allows for a cohesive ecosystem where AI models can seamlessly connect with an ever-growing array of external tools and data sources.

该架构看似简单，但其优势在于通信协议的标准化以及组件间职责的明确划分。这种设计构建了一个协同的生态系统，使人工智能模型能够与不断增多的外部工具和数据源无缝连接。


# Conclusion 结论

These interaction patterns are guided by several key principles that shape the design and evolution of MCP. The protocol emphasizes standardization by providing a universal protocol for AI connectivity, while maintaining simplicity by keeping the core protocol straightforward yet enabling advanced features. Safety is prioritized by requiring explicit user approval for sensitive operations, and discoverability enables dynamic discovery of capabilities. The protocol is built with extensibility in mind, supporting evolution through versioning and capability negotiation, and ensures interoperability across different implementations and environments.

这些交互模式由若干关键原则指导，这些原则塑造了MCP的设计和发展。该协议强调通过提供通用的AI连接协议来实现标准化</b0，同时通过保持核心协议的简洁性并支持高级功能来维持简单性</b1。安全性</b2是优先考虑的，要求敏感操作必须获得用户的明确批准，而可发现性则支持对功能的动态发现。该协议在设计时考虑了可扩展性</b3，通过版本控制和功能协商支持演进，并确保在不同实现和环境中的互操作性</b4。

In the next section, we’ll explore the communication protocol that enables these components to work together effectively.

在下一节中，我们将探讨使这些组件能够有效协同工作的通信协议。


